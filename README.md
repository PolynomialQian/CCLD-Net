# Boosting Medical Image Segmentation via Conditional-Synergistic Convolution and Lesion Decoupling

## Preface

This repo contains the source code and prediction maps of our ***CCLDNet*** and ***CCLDNet\****. 

## Update

:fire: **Update 2022/09/08** :fire: Our paper is now accepted by Computerized Medical Imaging and Graphics (CMIG). ([PDF](https://doi.org/10.1016/j.compmedimag.2022.102110))

## Dataset

* Datasets in use: 

  * Download EndoScene (912 pairs) ([source](https://www.hindawi.com/journals/jhe/2017/4037190/)) and put it into the `./data/TrainDataset_Endo`

  * Download ClinicDB (612 pairs), Kvasir (1000 pairs), ETIS (196 pairs), ColonDB (380 pairs), and EndoScene (300 pairs) ([source](https://github.com/DengPingFan/PraNet)), then put them into the `./data/TrainDataset_CVC_Kva`

  * Download ISIC 2018 (2594 pairs) ([source](https://challenge.isic-archive.com/data/)) and put it into the `./data/TrainDataset_ISIC_2018`

ðŸ’¡**Important tips**ðŸ’¡

  The center label and boundary label can be generated by `./utils/label.py`.

## Usage
### Repo clone

```bash
git clone https://github.com/QianChen98/CCLD-Net.git
cd CCLDNet
```

### Prerequisites

Required packages are listed below:

- `Ubuntu 16.04`
- `python=3.7`
- `pytorch>=1.7`
- `cuda>=10.1`

### Inference

* Download the pre-trained weights and save them as `./model_save/name/last.pth` (e.g. `./model_save/EndoScene_CCLDNet/last.pth` )

  * `large` means the pre-trained weights for ***CCLDNet\****
  * EndoScene_CCLDNet ([Baidu Cloud](https://pan.baidu.com/s/1P4OvVfzpfVbP3ZvOAG9xaQ), Fetch code: c4ed)
  * EndoScene_CCLDNet_large ([Baidu Cloud](https://pan.baidu.com/s/1mW4gqlCCX3TDKvkUtbVNXA), Fetch code: nqys)
  * CVC_Kva_CCLDNet ([Baidu Cloud](https://pan.baidu.com/s/1wV2wnFfkzk_Lsb2olQUacQ), Fetch code: z42k)
  * CVC_Kva_CCLDNet_large ([Baidu Cloud](https://pan.baidu.com/s/1wxnKzx-HMxVMmpI2p29FBg), Fetch code: af2o)
  * ISIC_2018_CCLDNet ([Baidu Cloud](https://pan.baidu.com/s/1bOpFkgme7bZeG9b-CuoS5g), Fetch code: lmyp)
  * ISIC_2018_CCLDNet_large ([Baidu Cloud](https://pan.baidu.com/s/1Ja_0IRDLUqlVxjpKbQmJZQ), Fetch code: abi8)

* Run the following command for testing: 
 ```bash

  # EndoScene
 python test.py --model_path ./model_save/EndoScene_CCLDNet/last.pth --swin_type base --crossnum endo --data_dir ./data/TrainDataset_Endo
 python test.py --model_path ./model_save/EndoScene_CCLDNet_large/last.pth --swin_type large --crossnum endo --data_dir ./data/TrainDataset_Endo
  # CVC_Kva
  python test.py --model_path ./model_save/CVC_Kva_CCLDNet/last.pth --swin_type base --crossnum CVC --data_dir ./data/TrainDataset_CVC_Kva
 python test.py --model_path ./model_save/CVC_Kva_CCLDNet_large/last.pth --swin_type large --crossnum CVC --data_dir ./data/TrainDataset_CVC_Kva
  # ISIC_2018
  python test.py --model_path ./model_save/ISIC_2018_CCLDNet/last1.pth --swin_type base --crossnum CA1 --data_dir ./data/TrainDataset_ISIC_2018
 python test.py --model_path ./model_save/ISIC_2018_CCLDNet_large/last1.pth --swin_type large --crossnum CA1 --data_dir ./data/TrainDataset_ISIC_2018
...
 python test.py --model_path ./model_save/ISIC_2018_CCLDNet/last5.pth --swin_type base --crossnum CA5 --data_dir ./data/TrainDataset_ISIC_2018
 python test.py --model_path ./model_save/ISIC_2018_CCLDNet_large/last5.pth --swin_type large --crossnum CA5 --data_dir ./data/TrainDataset_ISIC_2018
 ```
* Note that for researchers training with multiple GPUs, remember to add `--multi_load` to the inference command during testing.

### Training

* Run the following command for training (Note that the `type_name` below can be either `base` or `large`.): 
  ```bash
  
  # EndoScene
  python train.py --crossnum 'endo' --swin_type [type_name]  --data_dir ./data/TrainDataset_Endo  
  
  # CVC_Kva
  python train.py --crossnum 'CVC' --swin_type [type_name]  --data_dir ./data/TrainDataset_CVC_Kva  
  
  # ISIC_2018
  python train.py --crossnum 'CA1' --swin_type [type_name]  --data_dir ./data/TrainDataset_2018
  ...  
  python train.py --crossnum 'CA5' --swin_type [type_name]  --data_dir ./data/TrainDataset_2018
  ```

### Result

  * Qualitative performance

    Quantitative results in terms of Dice coefficient (Dice), Accuracy (Acc), Specificity (Spe), Jaccard index (Jac), Sensitivity (Sen) and mean absolute error (MAE). [Six datasets](#Dataset) are employed. For brevity, values in the table below are in the form of `CCLDNet|CCLDNet*`.

| Dataset                | Dice           | Jac            | Spe            | Acc            | Sen          | MAE        |
| ---------------------- | -------------- | -------------- | -------------- | -------------- | ------------ | ---------- |
| EndoScene (912 pairs)  | 88.51 \| 89.22 | 82.52 \| 83.36 | 99.67 \| 99.66 | 97.55 \| 97.65 | 87.67\|88.47 | 2.31\|2.21 |
| ClinicDB (612 pairs)   | 93.89 \| 94.02 | 89.56 \| 89.26 | 99.63 \| 99.51 | 99.39 \| 99.34 | 95.09\|94.57 | 0.49\|0.54 |
| Kvasir (1000 pairs)    | 91.73 \| 92.28 | 86.97 \| 87.78 | 99.03 \| 99.20 | 97.99 \| 98.02 | 90.65\|91.39 | 1.71\|1.66 |
| ColonDB (380 pairs)    | 78.64 \| 79.80 | 71.29 \| 72.55 | 98.88 \| 98.95 | 96.93 \| 96.90 | 81.64\|83.07 | 2.79\|2.83 |
| EndoScene (300 pairs)  | 87.92 \| 90.75 | 80.97 \| 83.96 | 99.36 \| 99.59 | 99.22 \| 99.45 | 95.46\|95.64 | 0.65\|0.48 |
| ETIS (196 pairs)       | 78.64 \| 77.53 | 71.34 \| 70.15 | 98.69 \| 98.99 | 98.42 \| 98.71 | 85.95\|84.62 | 1.37\|1.12 |
| ISIC 2018 (2594 pairs) | 90.97 \| 91.15 | 84.72 \| 84.99 | 97.65 \| 97.68 | 96.72 \| 96.76 | 91.56\|91.69 | 2.65\|2.58 |

* Downloading links of our result maps:

  * CCLDNet: [Baidu Cloud](https://pan.baidu.com/s/1xq-aGZ0ENBMkhknuQghtpA) (Fetch code: ussf)
  * CCLDNet_large: [Baidu Cloud](https://pan.baidu.com/s/1qH0UtwDehx-v0TUT_OR5jQ) (Fetch code: qpw3) 



